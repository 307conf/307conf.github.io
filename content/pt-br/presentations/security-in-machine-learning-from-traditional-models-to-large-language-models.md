+++
title = "Segurança em Machine Learning: Dos Modelos Tradicionais aos Large Language Models"
date = 2025-12-14T10:00:00-03:00
authors = ["erikson-julio-de-aguiar"]
track = "AI Village"
short_description = "Detecção e compreensão de ataques contra modelos de machine learning, dos modelos clássicos aos LLMs."
summary = "Erikson Júlio de Aguiar apresenta como ataques contra modelos de machine learning ocorrem e como ferramentas como o RADAR-MIX ajudam a detectar, analisar e compreender essas ameaças, especialmente em domínios sensíveis como a IA aplicada à saúde."
video_url = "https://www.youtube.com/live/lQz6038calQ?si=Dwbu2PfTLQA6Q3XT"
+++

Esta palestra explora o panorama de segurança de sistemas de Machine Learning, desde modelos tradicionais até Large Language Models (LLMs). A apresentação foca em como ataques adversariais se manifestam, onde eles ocorrem ao longo do pipeline de ML e por que compreender esses vetores é fundamental para manter sistemas confiáveis.

A sessão apresenta o **RADAR-MIX**, uma ferramenta desenvolvida para não apenas detectar ataques contra modelos de ML, mas também oferecer visibilidade sobre como e onde esses ataques acontecem. A discussão destaca a importância da robustez e da segurança em aplicações de alto impacto, especialmente em diagnósticos médicos, onde falhas podem gerar consequências reais e significativas.
