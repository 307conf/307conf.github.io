+++
title = "Security in Machine Learning: From Traditional Models to Large Language Models"
date = 2025-12-14T10:00:00-03:00
authors = ["erikson-julio-de-aguiar"]
track = "AI Village"
short_description = "Detecting and understanding attacks against machine learning models, from classical ML to LLMs."
summary = "Erikson JÃºlio de Aguiar presents how attacks against machine learning models occur and how tools like RADAR-MIX help detect, analyze, and understand these threats, especially in sensitive domains such as medical AI."
video_url = "https://www.youtube.com/live/lQz6038calQ?si=Dwbu2PfTLQA6Q3XT"
+++

This talk explores the security landscape of Machine Learning systems, from traditional models to Large Language Models (LLMs). The presentation focuses on how adversarial attacks manifest, where they occur within ML pipelines, and why understanding these vectors is critical for maintaining trustworthy systems.

The session introduces **RADAR-MIX**, a tool designed to not only detect attacks against ML models but also to provide visibility into how and where these attacks take place. The discussion highlights the importance of robustness and security in high-impact applications, particularly in medical diagnostics, where failures can have serious real-world consequences.
