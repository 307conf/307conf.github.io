+++
title = "Anthropic Attack"
date = 2025-12-14T10:50:00-03:00
authors = ["carlos-alcocer"]
track = "AI Village"
short_description = "Attacks, evasions, and security challenges targeting Anthropic language models."
summary = "Carlos Alcocer explores attacks and vulnerabilities targeting Anthropic AI models, analyzing evasion techniques, countermeasures, and how red teams challenge responsible AI systems."
video_url = "https://www.youtube.com/live/5GRQHp-Jujg?si=NRNIvmjb3ZXhlh88"
+++

This talk explores attacks and vulnerabilities specifically targeting Artificial Intelligence models developed by Anthropic, such as the **Claude** family. The session examines how these systems can be abused through evasion techniques, prompt manipulation, and unexpected model behaviors.

Countermeasures and security best practices required to ensure the integrity, reliability, and safety of these language models are discussed. The presentation offers a critical perspective on how *Red Teams* challenge the defenses of one of the leading companies in responsible AI, highlighting real-world risks and practical lessons for securing LLM-based systems.
